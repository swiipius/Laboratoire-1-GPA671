Exercice 1:
4. Pour chaque d√©tecteur, calculer la valeur de l'aire sous la courbe (Area Under Curve ou AUC). Commenter la m√©thode utilis√©e pour calculer l'aire et l'impact du choix de cette m√©thode sur l'indicateur de performance obtenu.
metrics.auc(x, y) avec x le array voulu en abscisses (ici: array tri√© de false positive rates) et y le array voulu en ordonn√©es (ici: array tri√© de rappels). La fonction utilise la m√©thode des trap√®zes pour assimiler l‚Äôaire sous la courbe. Avec cette m√©thode de calculation, l‚Äôindicateur est sous-estim√© ou sur-estim√© par rapport √† sa courbure: L‚Äôaire sous la courbe est sur-estim√© si la courbe est convexe, car une partie de l‚Äôaire au dessus de la courbe est tenue en compte en plus de l‚Äôaire enti√®rement en dessous. De la m√™me mani√®re, l‚Äôaire sous la courbe est sous-estim√© quand la courbe est concave.

6. Expliquer pourquoi le taux FPR n'est pas tr√®s indicatif dans ce cas de classification.
Dans ce cas de classification, nous n‚Äôavons pas toujours de vrai n√©gatifs pour tous le d√©tecteurs. Par cons√©quent, le taux FPR revient √† 1, car FP / (FP+TN) = FP / FP pour TN=0.


Exercice 2:
6. Expliquer pourquoi la courbe Pr√©cision-Rappel est plus adapt√©e pour mesurer les performances.
Ce qui nous int√©resse sur une m√©thode de classification, c‚Äôest l‚Äôidentification correcte d‚Äôun plus grand nombre de positifs et seulement de positifs. Donc, il suffit d‚Äôanalyser le nombre de positifs correctement identifi√©s par rapport √† ceux identifi√©s incorrectement comme positifs. Le taux de pr√©cision par rapport au rappel est alors plus adapt√© pour mesurer les performances que le taux FPR.


Exercice 3:
4. Impl√©menter la propagation directe dans la m√©thode forward du Perceptron avec la classe fournie ci-dessous. Calculer le taux d'exactitude avec les poids initiaux en utilisant la fonction forward. Commenter ce taux d'exactitude par rapport √† la figure g√©n√©r√©e pr√©c√©demment. Que faut-il ajouter dans le graphique pour correctement repr√©senter la fronti√®re de d√©cision?
Le taux d‚Äôexactitude prend en compte plus d‚Äôinformations que la fronti√®re de d√©cision seule. Le second indique seulement la classification d‚Äôapr√®s les calculs, alors que le premier exprime si la classification a √©t√© r√©ussie.
Pour correctement repr√©senter la fronti√®re de d√©cision, il faut indiquer dans le graphique, quel c√¥t√© repr√©sente quel d√©cision: classification positive ou n√©gative. √Ä ce but, nous pouvons nous servir de la normale.

5. Impl√©menter la mise √† jour des poids dans la m√©thode update. Pour cet exercice, la fonction update ne renvoie rien. Effectuer un ajustement des poids en utilisant le premier exemple et ùúÇ= 0.01. Dans le rapport, d√©tailler les calculs pour cette √©tape.
Des poids initiaux, on soustrait le gradient de la fonction de co√ªt par rapport aux poids multipli√© par le taux d‚Äôapprentissage. De cette mani√®re, on met √† jour le poids en fonction de 1% du co√ªt par rapport au poids pr√©c√©dent (avec ùúÇ= 0.01).

7. Continuer l‚Äôapprentissage en faisant 100 it√©rations sur l'ensemble les donn√©es. Tracer l‚Äô√©volution du taux d'exactitude avec chaque ajustement. Commenter la courbe.
Apr√®s 100 √©poques, le taux d‚Äôexactitude n‚Äôa pas encore atteint 100, mais 62,5%. Alors que, faisant 1000 √©poques, le taux d‚Äôexactitude atteint 100% √† la 139√®me √©poque.

9. Comment se termine l‚Äôapprentissage. Est-ce que l‚Äôalgorithme converge ? Expliquer pourquoi. Commenter le taux d'exactitude de la solution finale.
L‚Äôalgorithme converge au del√† de 139 √©poques ‚Äì le moment o√π le taux d‚Äôexactitude atteint 100%. La courbe sigmo√Øde classe les donn√©es et, apr√®s les nombreux it√©rations sur l‚Äôensemble des donn√©es, le perceptron est assez entra√Æn√© pour parfaitement classer toutes les donn√©es.

10. Que se passerait-il si on changeait l‚Äôordre de pr√©sentation des donn√©es ?
Avec les donn√©es m√©lang√©es al√©atoirement, le taux d‚Äôexactitude apr√®s 100 it√©rations est toujours √† 62,5%. Quant au moment de l‚Äôarriv√©e √† 100%, ceci s‚Äôest d√©cal√© d‚Äôune √©poque: Avec diff√©rentes permutations des donn√©es, le taux d‚Äôexactitude atteint 100% √† la 138√®me √©poque, soit une plus t√¥t qu‚Äôavec les donn√©es dans l‚Äôordre de l‚Äô√©nonc√©.


Exercice 4:
5. Comment se termine l‚Äôapprentissage. Est-ce que l‚Äôalgorithme converge ? Expliquer pourquoi. Commenter le taux d'exactitude de la solution finale.
XXXX

6. Que se passerait-il si on changeait l‚Äôordre de pr√©sentation des donn√©es ?
XXXX


Exercice 5:
2. Essayer d'autres configurations de r√©seaux multicouches (e.g. ajouter des couches, augmenter le nombre de neurones par couche, etc.) et de param√®tres d'entrainement (e.g. augmenter le taux d'apprentissage, faire plus d'it√©rations, etc.). Quel crit√®re avez-vous utilis√© pour arr√™ter valider l'entrainement ? Quel crit√®re avez-vous utilis√© pour comparer les diff√©rentes configurations ?
XXXX
